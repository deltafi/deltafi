## [1.1.14] - 2023-12-10

### Added
- Show `filteredContext` in UI for Actions in a `FILTERED` state.
- Allow separation of geneeral and detailed DeltaFile filtering reasons by adding optional (nullable) `filteredContext`to FilterResult
- New `namespace` and `node` tags for `gauge.app.memory` and `gauge.app.cpu` metrics
- New metric: `gauge.node.cpu.iowait` to track iowait pressure on nodes
- New dashboard: `DeltaFi > System Performance`
- Improved Server Sent Event error handling in the UI.
- CLI: Added `clear-memo` and `set-memo` options to timed-ingress commands
- New mutation `setTimedIngressMemo` allows the `memo` of a TimedIngressAction to be set (or cleared if `null`). The TimedIngress must not be RUNNING. Requires the ADMIN role

### Changed
- Improved error message and cause filtering on Errors and Filtered pages. 
- Improved `Clickhouse flows by annotation` dashboard with improved flow detail and summaries
- System Performance dashboard has gauges for CPU/RAM on each node
- System Overview has similar layout to the Flow By Annotation dashboard
- Flow By Annotation tables can be filtered and sorted
- CLI: mongodb commands updated to use mongosh and new environment variables

### Fixed
- Use the `created_before_index` for delete policies that are based on the created date
- DeltaFile stats metrics were not publishing
- Extraneous warning in clickhouse helm chart
- Disk usage bar chart fixed on System Overview
- Fixed naming of Flow By Annotation tables
- Removed deprecation warnings from mongo migrations
- KinD: Ingress NGINX initialization failure fixed by upgrading to newer ingress-nginx/controller image
- Fixed echo message in timed-ingress CLI
- Fixed GraphQL field name `filteredContext` in Action type to match Java
- Fixed support for FlowFile streaming (v2 and v3). A single FlowFile may result in multiple FlowFiles ingressed.
- Resolved a bug in the API that caused Server Sent Events to be initially sent with null values.

### Removed
- System Overview dashboard: Removed app CPU/RAM charts.  These charts were moved to the `System Performance` dashboard

### Tech-Debt/Refactor
- Query current action queue sizes from redis instead of graphite
- Move error acknowledged from partial index criteria to index field in mongo error index 
- Batched metrics in nodemonitor and clustermonitor to improve graphite performance
- Improve performance of the deltafi-monitor 
- Refactored collect (primarily by removing the READY_TO_COLLECT action state) to stop additional Mongo writes
- Reduce API memory footprint and CPU usage
- Decrease API response times for metrics/content requests
- Reduce delay before seeing initial status report when the UI is first loaded
- Change default number of API workers from 8 to 4
- API: Reduce memory usage and latency for content endpoint 
- API: Reduce memory allocation in survey endpoint
- Improve rebuild velocity for deltafi-api docker images

### Upgrade and Migration
- Dependency upgrades:
  - minio: quay.io/minio/minio:RELEASE.2023-12-02T10-51-33Z
  - promtail: grafana/promtail:2.9.2
  - loki: granfana/loki:2.9.2
  - registry: deltafi/registry:2.8.3-0
  - clickhouse: bitnami/clickhouse:23.10.5-debian-11-r0
- KinD: k8s.gcr.io/ingress-nginx/controller:v1.2.1
- New versions of dependent subsystems:
  - deltafi/grafana:10.2.2-0 (Grafana 10.2.2)
- Java dependency updates, including:
  - DGS: 7.5.3 -> 7.6.0
  - Jackson: 2.15.2 -> 2.16.0
  - Spring Boot: 3.0.11 -> 3.1.5
- Helm chart upgrades
  - minio - 5.0.9
  - mongodb - 14.4.0
  - redis - 18.4.0
  - kubernetes-dashboard - 6.0.8
  - promtail - 6.15.2
  - loki - 2.16.0
  - grafana - 7.0.11
  - clickhouse - 4.1.8
- When installing this version, mongodb will be updated and due to a bug in mongodb rolling initialization, the mongodb pod in a kubernetes cluster should be scaled to 0 instances:
```bash
# Prior to upgrade, scale the deltafi-mongodb pod to 0
kubectl scale deploy deltafi-mongodb --replicas=0
# During upgrade, after helm starts, scale the deltafi-mongodb pod to 1
kubectl scale deploy deltafi-mongodb --replicas=1
```

